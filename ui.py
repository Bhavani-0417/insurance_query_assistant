# app/ui.py
import os
import shutil
import json
from datetime import datetime
import streamlit as st
from build_index import build_index
from api import query_insurance_llm
from retriever import get_top_chunks
from app.embedder import embed_query_texts

st.set_page_config(page_title="ğŸ›¡ï¸ Insurance Document Query Assistant")
st.title("ğŸ›¡ï¸ Insurance Document Query Assistant")
st.markdown("Ask any question based on the uploaded insurance policy documents.")

# ğŸ“ PDF Upload Section
st.sidebar.header("ğŸ“„ Upload New PDF")
uploaded_file = st.sidebar.file_uploader("Upload a PDF", type=["pdf"])

if uploaded_file:
    # Save to data/ folder
    save_path = os.path.join("data", uploaded_file.name)
    with open(save_path, "wb") as f:
        shutil.copyfileobj(uploaded_file, f)

    st.sidebar.success(f"âœ… Uploaded: {uploaded_file.name}")
    
    # Rebuild the index
    with st.spinner("ğŸ”„ Rebuilding vector index..."):
        build_index()
        st.sidebar.success("âœ… Index rebuilt with new document!")
# ğŸ“œ View Query Logs
st.sidebar.header("ğŸ“œ View Query Logs")

if os.path.exists("output/query_logs.jsonl"):
    with st.sidebar.expander("Show Past Queries"):
        with open("output/query_logs.jsonl", "r", encoding="utf-8") as f:
            logs = [json.loads(line) for line in f.readlines()[-5:]]  # Show last 5 entries

        for i, log in enumerate(reversed(logs), 1):
            st.sidebar.markdown(f"**{i}. [{log['timestamp']}]**")
            st.sidebar.markdown(f"- â“ **Question:** {log['question']}")
            if 'decision' in log['response']:
                st.sidebar.markdown(f"- âœ… **Decision:** {log['response']['decision']}")
            else:
                st.sidebar.markdown(f"- ğŸ¤– **Response:** {str(log['response'])[:100]}...")
            st.sidebar.markdown("---")
else:
    st.sidebar.info("â„¹ï¸ No logs found yet.")

# ğŸ’¬ Question Input
user_input = st.text_input("ğŸ“¤ Enter your question:")

if st.button("Submit") and user_input.strip():
    with st.spinner("ğŸ” Analyzing your question..."):
        # Step 1: Retrieve relevant chunks
        retrieved_docs = get_top_chunks(user_input, embed_query_texts, top_k=3)

        # Show retrieved chunks in sidebar
        st.sidebar.header("ğŸ“„ Top Retrieved Chunks")
        for i, chunk in enumerate(retrieved_docs, 1):
            st.sidebar.markdown(f"**Chunk {i}:**\n\n{str(chunk)[:500]}...")

        # Step 2: Query the LLM
        result = query_insurance_llm(user_input, retrieved_docs)

        # Step 3: Log the interaction
        log_entry = {
            "timestamp": str(datetime.now()),
            "question": user_input,
            "retrieved_chunks": retrieved_docs,
            "response": result
        }

        os.makedirs("output", exist_ok=True)
        with open("output/query_logs.jsonl", "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")

        # Step 4: Show result to user
        if "error" in result:
            st.error(f"âŒ Error: {result['error']}")
        else:
            if "decision" in result:
                st.success(f"âœ… Decision: {result['decision']}")
                st.write(f"ğŸ’° Amount: {result.get('amount', 'N/A')}")
                st.write(f"ğŸ“„ Justification: {result.get('justification', 'N/A')}")
            else:
                st.write("ğŸ¤– Response:")
                st.json(result)
